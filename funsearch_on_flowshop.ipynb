{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14141f33cfbaa4b3",
   "metadata": {},
   "source": [
    "# Flow-Shop Problem-Solving with Google `FunSearch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574018938f2cee9",
   "metadata": {},
   "source": [
    "> Authors: CUI Guangyuan, XU Zhuojun, LI Songyan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1064f39f011527",
   "metadata": {},
   "source": [
    "This notebook is the main entrance of our work on the flow-shop problems' solving using Google `FunSearch` via various attempts. Mainly, the applications of existing methods on the problem-solving can be divided into three categories: baseline experiments including the applications of Google `FunSearch` and `OR-Tools` as well as the existing heuristics (only NEH algorithm). New approaches are also proposed in this research, including:\n",
    "\n",
    "- Trials on different kinds of prompts (Prompt Engineering)\n",
    "- FunSearch with Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61414801e69a5f2d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc7fa426bcdefd",
   "metadata": {},
   "source": [
    "## Baseline Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf275618774b36f9",
   "metadata": {},
   "source": [
    "### Existing Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47565fdd3559094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Parse the input data\n",
    "def parse_input(input_data):\n",
    "    lines = input_data.strip().split('\\n')\n",
    "    n_jobs, n_machines = map(int, lines[0].split())\n",
    "    \n",
    "    jobs = []\n",
    "    for i in range(1, n_jobs + 1):\n",
    "        job_data = lines[i].split()\n",
    "        job = []\n",
    "        for j in range(0, 2 * n_machines, 2):\n",
    "            machine = int(job_data[j])\n",
    "            processing_time = int(job_data[j + 1])\n",
    "            job.append((machine, processing_time))\n",
    "        jobs.append(job)\n",
    "    \n",
    "    return n_jobs, n_machines, jobs\n",
    "\n",
    "# Calculate makespan for a given job sequence\n",
    "def calculate_makespan(jobs, job_sequence, n_machines):\n",
    "    machine_times = [0] * n_machines\n",
    "    \n",
    "    for job_idx in job_sequence:\n",
    "        job = jobs[job_idx]\n",
    "        for (machine, processing_time) in job:\n",
    "            if machine == 0:\n",
    "                machine_times[machine] = machine_times[machine] + processing_time\n",
    "            else:\n",
    "                machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + processing_time\n",
    "    \n",
    "    return machine_times[-1]\n",
    "\n",
    "# Function to visualize the schedule\n",
    "def visualize_schedule(jobs, job_sequence, n_machines, algorithm_name):\n",
    "    # Calculate start and end times for each operation\n",
    "    machine_times = [0] * n_machines\n",
    "    schedule = []\n",
    "    \n",
    "    for job_idx in job_sequence:\n",
    "        job = jobs[job_idx]\n",
    "        job_schedule = []\n",
    "        \n",
    "        for machine, processing_time in job:\n",
    "            if machine == 0:\n",
    "                start_time = machine_times[machine]\n",
    "            else:\n",
    "                start_time = max(machine_times[machine], machine_times[machine - 1])\n",
    "            \n",
    "            end_time = start_time + processing_time\n",
    "            machine_times[machine] = end_time\n",
    "            job_schedule.append((machine, start_time, end_time))\n",
    "        \n",
    "        schedule.append(job_schedule)\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Define colors for jobs\n",
    "    colors = plt.cm.tab10.colors\n",
    "    \n",
    "    # Plot each operation\n",
    "    for i, job_schedule in enumerate(schedule):\n",
    "        job_idx = job_sequence[i]\n",
    "        for machine, start, end in job_schedule:\n",
    "            ax.barh(machine, end - start, left=start, height=0.8, \n",
    "                   color=colors[job_idx % len(colors)], alpha=0.8,\n",
    "                   edgecolor='black', linewidth=1)\n",
    "            \n",
    "            # Add job number label\n",
    "            if end - start > 30:  # Only add text if bar is wide enough\n",
    "                ax.text(start + (end - start) / 2, machine, f'J{job_idx}', \n",
    "                       ha='center', va='center', color='black', fontweight='bold')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [Patch(facecolor=colors[i % len(colors)], edgecolor='black', label=f'Job {i}')\n",
    "                      for i in range(len(jobs))]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machine')\n",
    "    ax.set_yticks(range(n_machines))\n",
    "    ax.set_yticklabels([f'Machine {i}' for i in range(n_machines)])\n",
    "    ax.set_title(f'Flow Shop Schedule - {algorithm_name}\\nMakespan: {machine_times[-1]}')\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# NEH Algorithm\n",
    "def neh_algorithm(jobs, n_jobs, n_machines):\n",
    "    # Calculate total processing time for each job\n",
    "    job_times = []\n",
    "    for i, job in enumerate(jobs):\n",
    "        total_time = sum(time for _, time in job)\n",
    "        job_times.append((i, total_time))\n",
    "    \n",
    "    # Sort jobs by total processing time (descending)\n",
    "    job_times.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Build sequence incrementally\n",
    "    sequence = [job_times[0][0]]\n",
    "    \n",
    "    for i in range(1, n_jobs):\n",
    "        job_idx = job_times[i][0]\n",
    "        best_makespan = float('inf')\n",
    "        best_position = 0\n",
    "        \n",
    "        # Try inserting the job at each possible position\n",
    "        for j in range(len(sequence) + 1):\n",
    "            test_sequence = sequence.copy()\n",
    "            test_sequence.insert(j, job_idx)\n",
    "            makespan = calculate_makespan(jobs, test_sequence, n_machines)\n",
    "            \n",
    "            if makespan < best_makespan:\n",
    "                best_makespan = makespan\n",
    "                best_position = j\n",
    "        \n",
    "        sequence.insert(best_position, job_idx)\n",
    "    \n",
    "    makespan = calculate_makespan(jobs, sequence, n_machines)\n",
    "    return sequence, makespan\n",
    "\n",
    "# Main function to run and compare all algorithms\n",
    "def main():\n",
    "    # Test instance\n",
    "    input_data = \"\"\"11 5\n",
    "0 375 1 12 2 142 3 245 4 412\n",
    "0 632 1 452 2 758 3 278 4 398\n",
    "0 12 1 876 2 124 3 534 4 765\n",
    "0 460 1 542 2 523 3 120 4 499\n",
    "0 528 1 101 2 789 3 124 4 999\n",
    "0 796 1 245 2 632 3 375 4 123\n",
    "0 532 1 230 2 543 3 896 4 452\n",
    "0 14 1 124 2 214 3 543 4 785\n",
    "0 257 1 527 2 753 3 210 4 463\n",
    "0 896 1 896 2 214 3 258 4 259\n",
    "0 532 1 302 2 501 3 765 4 988\"\"\"\n",
    "    \n",
    "    n_jobs, n_machines, jobs = parse_input(input_data)\n",
    "    \n",
    "    print(f\"Problem: {n_jobs} jobs, {n_machines} machines\")\n",
    "    \n",
    "    # Run and time each algorithm\n",
    "    algorithms = [\n",
    "        (\"NEH Algorithm\", lambda: neh_algorithm(jobs, n_jobs, n_machines)),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, algorithm in algorithms:\n",
    "        print(f\"\\nRunning {name}...\")\n",
    "        start_time = time.time()\n",
    "        sequence, makespan = algorithm()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        execution_time = end_time - start_time\n",
    "        results.append((name, sequence, makespan, execution_time))\n",
    "        \n",
    "        print(f\"  Sequence: {sequence}\")\n",
    "        print(f\"  Makespan: {makespan}\")\n",
    "        print(f\"  Time: {execution_time:.6f} seconds\")\n",
    "        \n",
    "        # Create visualization\n",
    "        fig = visualize_schedule(jobs, sequence, n_machines, name)\n",
    "        plt.savefig(f\"{name.replace(' ', '_')}_schedule.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\nComparison of Algorithms:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Algorithm':<20} {'Makespan':<10} {'Time (s)':<15} {'Relative Quality':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    best_makespan = min(result[2] for result in results)\n",
    "    \n",
    "    for name, sequence, makespan, execution_time in results:\n",
    "        relative_quality = (makespan / best_makespan - 1) * 100  # percentage above best\n",
    "        print(f\"{name:<20} {makespan:<10} {execution_time:<15.6f} {relative_quality:<15.2f}%\")\n",
    "    \n",
    "    # Create comparison bar charts\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Makespan comparison\n",
    "    algorithm_names = [result[0] for result in results]\n",
    "    makespans = [result[2] for result in results]\n",
    "    ax1.bar(algorithm_names, makespans, color='skyblue')\n",
    "    ax1.set_title('Makespan Comparison')\n",
    "    ax1.set_ylabel('Makespan')\n",
    "    ax1.set_xticklabels(algorithm_names, rotation=45, ha='right')\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Execution time comparison (log scale)\n",
    "    execution_times = [result[3] for result in results]\n",
    "    ax2.bar(algorithm_names, execution_times, color='salmon')\n",
    "    ax2.set_title('Execution Time Comparison')\n",
    "    ax2.set_ylabel('Time (seconds)')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_xticklabels(algorithm_names, rotation=45, ha='right')\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"algorithm_comparison.png\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49b89abedee41c",
   "metadata": {},
   "source": [
    "### Google `OR-Tools`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e98f762279b6b",
   "metadata": {},
   "source": [
    "Import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092ed648058f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "from ortools.sat.python import cp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d98b25a41f214f",
   "metadata": {},
   "source": [
    "Define the function to read cases from instances in desired formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c426f7ddad71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cases(path):\n",
    "    cases = []\n",
    "    with open(path, 'r') as f:\n",
    "        alldata = f.readlines()\n",
    "        first_line = alldata[0].split()\n",
    "        n_jobs, n_machines = int(first_line[0]), int(first_line[1])\n",
    "\n",
    "        for i in range(1, len(alldata)):\n",
    "            line = alldata[i]\n",
    "            jobs_cases = []\n",
    "            data = line.split()\n",
    "            for d in range(0, len(data), 2):\n",
    "                jobs_cases.append((int(data[d]), int(data[d+1])))\n",
    "            cases.append(jobs_cases)\n",
    "\n",
    "    return (n_jobs, n_machines), cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cfd6bd088680e",
   "metadata": {},
   "source": [
    "Define the function for plotting Gantt chart of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e83e4e0021da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gantt_chart(result_job_schedule, num_jobs, num_machines,\n",
    "                     title=\"Flow-Shop Gantt Chart\"):\n",
    "    fig, ax = plt.subplots(figsize=(25, 12))\n",
    "\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    if num_jobs > len(colors):\n",
    "        random.seed(4487)\n",
    "        colors = []\n",
    "        for _ in range(num_jobs):\n",
    "            colors.append(f'#{random.randint(0, 0xFFFFFF):06x}')\n",
    "\n",
    "    for job_id, machine_id, stime, etime in result_job_schedule:\n",
    "        duration = etime - stime\n",
    "        rect = patches.Rectangle(\n",
    "            (stime, num_machines - machine_id - 1),\n",
    "            duration,\n",
    "            0.8,\n",
    "            linewidth=1,\n",
    "            edgecolor='black',\n",
    "            facecolor=colors[job_id],\n",
    "            alpha=0.6,\n",
    "            label=f'Job-{job_id}' if machine_id == 0 else ''\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        rx, ry = rect.get_xy()\n",
    "        ax.text(\n",
    "            rx + duration / 2,\n",
    "            ry + 0.4,\n",
    "            f'J{job_id}',\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            color='black',\n",
    "            fontweight='light'\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, max([endtime for _, _, _, endtime in result_job_schedule]) + 1)\n",
    "    ax.set_ylim(0, num_machines)\n",
    "\n",
    "    ax.set_yticks(np.arange(num_machines) + 0.4)\n",
    "    ax.set_yticklabels([f'Machine {num_machines - i - 1}' for i in range(num_machines)])\n",
    "\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "    handles = [patches.Patch(color=colors[i], label=f'Job {i}') for i in range(num_jobs)]\n",
    "    ax.legend(handles=handles, loc='upper right', ncol=min(5, num_jobs))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machines')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebdd3a7e3355d",
   "metadata": {},
   "source": [
    "Define the main process of problem solving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9951b423873df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_flowshop(num_jobs, num_machines, jobs_data):\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "\n",
    "    \"\"\"Create interval variables\"\"\"\n",
    "    intervals = {}\n",
    "    for job_id in range(num_jobs):\n",
    "        for task_id, (machine_id, duration) in enumerate(jobs_data[job_id]):\n",
    "            # a job is consisted of multiple tasks\n",
    "\n",
    "            unique_id = f'{job_id}-{machine_id}-{task_id}'\n",
    "            start = model.NewIntVar(0, 10000, f's-{unique_id}')\n",
    "            end = model.NewIntVar(0, 10000, f'e-{unique_id}')\n",
    "            interval = model.NewIntervalVar(start, duration, end, f'interval-{unique_id}')\n",
    "\n",
    "            # uniquely identified by job ID and machine ID\n",
    "            # since a task can only be executed on a machine\n",
    "            intervals[(job_id, machine_id)] = (start, end, interval)\n",
    "\n",
    "\n",
    "    \"\"\"Add constraints on the order\"\"\"\n",
    "    for job_id in range(num_jobs):\n",
    "        for task_id in range(1, num_machines):\n",
    "            # (task number = machine number) in flow-shop\n",
    "\n",
    "            prev_task_machine = jobs_data[job_id][task_id - 1][0]\n",
    "            cur_task_machine = jobs_data[job_id][task_id][0]\n",
    "\n",
    "            # start time of current task must be larger than the end time of previous task\n",
    "            model.Add(intervals[(job_id, cur_task_machine)][0]\n",
    "                      >= intervals[(job_id, prev_task_machine)][1])\n",
    "\n",
    "\n",
    "    \"\"\"Add constraints on the machine conflicts\"\"\"\n",
    "    for machine_id in range(num_machines):\n",
    "        machine_intervals = [\n",
    "            intervals[(job_id, machine_id)][2]\n",
    "            for job_id in range(num_jobs)\n",
    "        ]\n",
    "        model.AddNoOverlap(machine_intervals)\n",
    "\n",
    "\n",
    "    \"\"\"Setting Objects\"\"\"\n",
    "    case_object = model.NewIntVar(0, 10000, 'makespan')\n",
    "    model.AddMaxEquality(case_object, [\n",
    "        intervals[(job_id, num_machines-1)][1]\n",
    "        for job_id in range(num_jobs)\n",
    "    ])\n",
    "    model.Minimize(case_object)\n",
    "\n",
    "\n",
    "    \"\"\"Solving\"\"\"\n",
    "    solver = cp_model.CpSolver()\n",
    "    stat = solver.Solve(model)\n",
    "\n",
    "\n",
    "    \"\"\"Results\"\"\"\n",
    "    result_schedule = []\n",
    "    if stat == cp_model.OPTIMAL:\n",
    "        # exists optimal solution\n",
    "        print(f'Optimal Makespan: {solver.ObjectiveValue()}')\n",
    "        for job_id in range(num_jobs):\n",
    "            for machine_id in range(num_machines):\n",
    "                start = solver.Value(intervals[(job_id, machine_id)][0])\n",
    "                duration = jobs_data[job_id][machine_id][1]\n",
    "                end = start + duration\n",
    "                print(f'Task-{machine_id} of Job-{job_id} is scheduled on Machine-{machine_id}: {start} ~ {end}')\n",
    "                result_schedule.append((job_id, machine_id, start, end))\n",
    "    else:\n",
    "        # No optimal solution\n",
    "        print('No solution found')\n",
    "\n",
    "    return result_schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f7a580594556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_set_name = 'reeves'\n",
    "case_no = 20\n",
    "case_path = f'../data/{case_set_name}/{case_set_name}{case_no}.txt'\n",
    "\n",
    "(n_jobs, n_machines), jobs_data = read_cases(case_path)\n",
    "result_schedule = solve_flowshop(n_jobs, n_machines, jobs_data)\n",
    "\n",
    "plot_gantt_chart(result_schedule, n_jobs, n_machines, f'Result of case: {case_set_name}-{case_no}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1763bf6debef67",
   "metadata": {},
   "source": [
    "### Naïve Application on FunSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18b2dae9c8ce707",
   "metadata": {},
   "source": [
    "## New Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd4c0dba4b1330",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638285dcccf1a8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faf527d2cdc8a943",
   "metadata": {},
   "source": [
    "### FunSearch with Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8babde0e35b8e83c",
   "metadata": {},
   "source": [
    "This is our key improvements that has made on the basic FunSearch Framework. The main idea of the new framework is applying Curriculum Learning in the evolving process of FunSearch.\n",
    "\n",
    "Specifically, a single iteration of evolving are now turned into multiple iterations. In this framework, we call them 'Stages':\n",
    "- The input instances are divided into various stages, starting from 'easy' instances all the way up to 'complicated' instances\n",
    "    - Degrees of complication are defined manually\n",
    "- At each stage, FunSearch is executed only with the instances belong to that stage, and gets the result\n",
    "- If the result of current stage is higher than the baseline score, then it enters the next stage, namely a more complicated stage\n",
    "    - Baseline function that provides baseline score is given by the raw function at each stage before the actual evolving\n",
    "- If the result of current stage is lower than the baseline score, it keeps trying until it reaches the maximum number of attempts defined in advance, or gets a better score and escape current stage\n",
    "- The final output of this framework can either be the 'half-evolved' or 'completely-evolved' function due to the maximum attempts limit\n",
    "\n",
    "> See directory `implementation_cl` for the detailed implementation of this framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d2cc54cb3112a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6537eeb104fb003",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830d4e068c651b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
