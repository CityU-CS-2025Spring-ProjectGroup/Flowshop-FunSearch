{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14141f33cfbaa4b3",
   "metadata": {},
   "source": [
    "# Flow-Shop Problem-Solving with Google `FunSearch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574018938f2cee9",
   "metadata": {},
   "source": [
    "> Authors: CUI Guangyuan, LI Songyan, XU Zhuojun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1064f39f011527",
   "metadata": {},
   "source": [
    "This notebook is the main entrance of our work on the flow-shop problems' solving using Google `FunSearch` via various attempts. Mainly, the applications of existing methods on the problem-solving can be divided into three categories: baseline experiments including the applications of Google `FunSearch` and `OR-Tools` as well as the existing heuristics (only NEH algorithm). New approaches are also proposed in this research, including:\n",
    "\n",
    "- Trials on different kinds of prompts (Prompt Engineering)\n",
    "- FunSearch with Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add8e30",
   "metadata": {},
   "source": [
    "> Environment setup before the execution (**IMPORTANT**):\n",
    "> - Our experiments are operated under the anaconda virtual environment\n",
    ">\n",
    "> You can follow the instructions below to setup the correct environment:\n",
    "> - `conda create -n funsearch_env -f environment.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61414801e69a5f2d",
   "metadata": {},
   "source": [
    "## Dataset for Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c2ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1 = \"data/carlier/carlier1.txt\"\n",
    "instance2 = \"data/carlier/carlier2.txt\"\n",
    "instance3 = \"data/heller/heller1.txt\"\n",
    "instance4 = \"data/heller/heller2.txt\"\n",
    "instance5 = \"data/reeves/reeves1.txt\"\n",
    "instance6 = \"data/reeves/reeves2.txt\"\n",
    "instance7 = \"data/reeves/reeves3.txt\"\n",
    "\n",
    "instances = [\n",
    "    instance1,\n",
    "    instance2,\n",
    "    instance3,\n",
    "    instance4,\n",
    "    instance5,\n",
    "    instance6,\n",
    "    instance7\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc7fa426bcdefd",
   "metadata": {},
   "source": [
    "## Baseline Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf275618774b36f9",
   "metadata": {},
   "source": [
    "### Existing Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a2a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9fce0",
   "metadata": {},
   "source": [
    "Parse the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d6a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(input_data):\n",
    "    lines = input_data.strip().split('\\n')\n",
    "    n_jobs, n_machines = map(int, lines[0].split())\n",
    "    \n",
    "    jobs = []\n",
    "    for i in range(1, n_jobs + 1):\n",
    "        job_data = lines[i].split()\n",
    "        job = []\n",
    "        for j in range(0, 2 * n_machines, 2):\n",
    "            machine = int(job_data[j])\n",
    "            processing_time = int(job_data[j + 1])\n",
    "            job.append((machine, processing_time))\n",
    "        jobs.append(job)\n",
    "    \n",
    "    return n_jobs, n_machines, jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3b69a",
   "metadata": {},
   "source": [
    "Calculate makespan for a given job sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc43584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_makespan(jobs, job_sequence, n_machines):\n",
    "    machine_times = [0] * n_machines\n",
    "    \n",
    "    for job_idx in job_sequence:\n",
    "        job = jobs[job_idx]\n",
    "        for (machine, processing_time) in job:\n",
    "            if machine == 0:\n",
    "                machine_times[machine] = machine_times[machine] + processing_time\n",
    "            else:\n",
    "                machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + processing_time\n",
    "    \n",
    "    return machine_times[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f625f45",
   "metadata": {},
   "source": [
    "Function to visualize the schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f00037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_schedule(jobs, job_sequence, n_machines, algorithm_name):\n",
    "    # Calculate start and end times for each operation\n",
    "    machine_times = [0] * n_machines\n",
    "    schedule = []\n",
    "    \n",
    "    for job_idx in job_sequence:\n",
    "        job = jobs[job_idx]\n",
    "        job_schedule = []\n",
    "        \n",
    "        for machine, processing_time in job:\n",
    "            if machine == 0:\n",
    "                start_time = machine_times[machine]\n",
    "            else:\n",
    "                start_time = max(machine_times[machine], machine_times[machine - 1])\n",
    "            \n",
    "            end_time = start_time + processing_time\n",
    "            machine_times[machine] = end_time\n",
    "            job_schedule.append((machine, start_time, end_time))\n",
    "        \n",
    "        schedule.append(job_schedule)\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Define colors for jobs\n",
    "    colors = plt.cm.tab10.colors\n",
    "    \n",
    "    # Plot each operation\n",
    "    for i, job_schedule in enumerate(schedule):\n",
    "        job_idx = job_sequence[i]\n",
    "        for machine, start, end in job_schedule:\n",
    "            ax.barh(machine, end - start, left=start, height=0.8, \n",
    "                   color=colors[job_idx % len(colors)], alpha=0.8,\n",
    "                   edgecolor='black', linewidth=1)\n",
    "            \n",
    "            # Add job number label\n",
    "            if end - start > 30:  # Only add text if bar is wide enough\n",
    "                ax.text(start + (end - start) / 2, machine, f'J{job_idx}', \n",
    "                       ha='center', va='center', color='black', fontweight='bold')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [Patch(facecolor=colors[i % len(colors)], edgecolor='black', label=f'Job {i}')\n",
    "                      for i in range(len(jobs))]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machine')\n",
    "    ax.set_yticks(range(n_machines))\n",
    "    ax.set_yticklabels([f'Machine {i}' for i in range(n_machines)])\n",
    "    ax.set_title(f'Flow Shop Schedule - {algorithm_name}\\nMakespan: {machine_times[-1]}')\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d0943",
   "metadata": {},
   "source": [
    "Definition of NEH algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e282b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_algorithm(jobs, n_jobs, n_machines):\n",
    "    # Calculate total processing time for each job\n",
    "    job_times = []\n",
    "    for i, job in enumerate(jobs):\n",
    "        total_time = sum(time for _, time in job)\n",
    "        job_times.append((i, total_time))\n",
    "    \n",
    "    # Sort jobs by total processing time (descending)\n",
    "    job_times.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Build sequence incrementally\n",
    "    sequence = [job_times[0][0]]\n",
    "    \n",
    "    for i in range(1, n_jobs):\n",
    "        job_idx = job_times[i][0]\n",
    "        best_makespan = float('inf')\n",
    "        best_position = 0\n",
    "        \n",
    "        # Try inserting the job at each possible position\n",
    "        for j in range(len(sequence) + 1):\n",
    "            test_sequence = sequence.copy()\n",
    "            test_sequence.insert(j, job_idx)\n",
    "            makespan = calculate_makespan(jobs, test_sequence, n_machines)\n",
    "            \n",
    "            if makespan < best_makespan:\n",
    "                best_makespan = makespan\n",
    "                best_position = j\n",
    "        \n",
    "        sequence.insert(best_position, job_idx)\n",
    "    \n",
    "    makespan = calculate_makespan(jobs, sequence, n_machines)\n",
    "    return sequence, makespan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006cff4",
   "metadata": {},
   "source": [
    "Run and evaluate original NEH algorithm as the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47565fdd3559094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: data/carlier/carlier1.txt | Jobs: 11 | Machines: 5\n",
      "Running NEH...\n",
      "  Sequence: [7, 0, 4, 8, 2, 10, 3, 6, 5, 1, 9]\n",
      "  Makespan: 7038\n",
      "  Time: 0.000344 seconds\n",
      "\n",
      "Problem: data/carlier/carlier2.txt | Jobs: 13 | Machines: 4\n",
      "Running NEH...\n",
      "  Sequence: [6, 10, 2, 12, 3, 4, 0, 1, 8, 7, 11, 5, 9]\n",
      "  Makespan: 7376\n",
      "  Time: 0.000547 seconds\n",
      "\n",
      "Problem: data/heller/heller1.txt | Jobs: 100 | Machines: 10\n",
      "Running NEH...\n",
      "  Sequence: [36, 62, 0, 26, 21, 73, 56, 17, 98, 83, 15, 16, 53, 75, 94, 71, 4, 59, 34, 68, 87, 96, 97, 58, 12, 65, 82, 41, 70, 66, 22, 81, 25, 50, 8, 78, 45, 49, 48, 10, 90, 85, 43, 64, 14, 13, 86, 61, 1, 89, 42, 92, 63, 99, 76, 5, 91, 28, 19, 20, 39, 2, 47, 31, 52, 7, 80, 72, 27, 18, 67, 60, 29, 95, 40, 24, 54, 38, 23, 32, 37, 35, 57, 77, 84, 88, 51, 69, 33, 9, 6, 3, 79, 11, 44, 93, 55, 30, 74, 46]\n",
      "  Makespan: 519\n",
      "  Time: 0.402219 seconds\n",
      "\n",
      "Problem: data/heller/heller2.txt | Jobs: 20 | Machines: 10\n",
      "Running NEH...\n",
      "  Sequence: [0, 3, 11, 8, 14, 16, 1, 12, 15, 7, 19, 18, 10, 5, 17, 4, 13, 2, 9, 6]\n",
      "  Makespan: 141\n",
      "  Time: 0.003327 seconds\n",
      "\n",
      "Problem: data/reeves/reeves1.txt | Jobs: 20 | Machines: 5\n",
      "Running NEH...\n",
      "  Sequence: [5, 8, 11, 17, 13, 1, 16, 14, 2, 0, 6, 19, 12, 3, 10, 15, 7, 9, 4, 18]\n",
      "  Makespan: 1303\n",
      "  Time: 0.001680 seconds\n",
      "\n",
      "Problem: data/reeves/reeves2.txt | Jobs: 20 | Machines: 5\n",
      "Running NEH...\n",
      "  Sequence: [13, 18, 4, 0, 3, 1, 8, 7, 11, 12, 6, 2, 16, 15, 9, 5, 10, 17, 14, 19]\n",
      "  Makespan: 1132\n",
      "  Time: 0.001693 seconds\n",
      "\n",
      "Problem: data/reeves/reeves3.txt | Jobs: 20 | Machines: 5\n",
      "Running NEH...\n",
      "  Sequence: [18, 7, 11, 15, 19, 4, 0, 9, 12, 2, 1, 17, 8, 6, 5, 10, 3, 14, 13, 16]\n",
      "  Makespan: 1281\n",
      "  Time: 0.001663 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ins in instances:\n",
    "    with open(ins, 'r') as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    n_jobs, n_machines, jobs = parse_input(input_data)\n",
    "\n",
    "    print(f\"Problem: {ins} | Jobs: {n_jobs} | Machines: {n_machines}\")\n",
    "\n",
    "    print(f\"Running NEH...\")\n",
    "    start_time = time.time()\n",
    "    sequence, makespan = neh_algorithm(jobs, n_jobs, n_machines)\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(f\"  Sequence: {sequence}\")\n",
    "    print(f\"  Makespan: {makespan}\")\n",
    "    print(f\"  Time: {execution_time:.6f} seconds\\n\")\n",
    "\n",
    "    # fig = visualize_schedule(jobs, sequence, n_machines, 'NEH')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49b89abedee41c",
   "metadata": {},
   "source": [
    "### Google `OR-Tools`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e98f762279b6b",
   "metadata": {},
   "source": [
    "Import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5092ed648058f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "from ortools.sat.python import cp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d98b25a41f214f",
   "metadata": {},
   "source": [
    "Define the function to read cases from instances in desired formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53c426f7ddad71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cases(path):\n",
    "    cases = []\n",
    "    with open(path, 'r') as f:\n",
    "        alldata = f.readlines()\n",
    "        first_line = alldata[0].split()\n",
    "        n_jobs, n_machines = int(first_line[0]), int(first_line[1])\n",
    "\n",
    "        for i in range(1, len(alldata)):\n",
    "            line = alldata[i]\n",
    "            jobs_cases = []\n",
    "            data = line.split()\n",
    "            for d in range(0, len(data), 2):\n",
    "                jobs_cases.append((int(data[d]), int(data[d+1])))\n",
    "            cases.append(jobs_cases)\n",
    "\n",
    "    return (n_jobs, n_machines), cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cfd6bd088680e",
   "metadata": {},
   "source": [
    "Define the function for plotting Gantt chart of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530e83e4e0021da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gantt_chart(result_job_schedule, num_jobs, num_machines,\n",
    "                     title=\"Flow-Shop Gantt Chart\"):\n",
    "    fig, ax = plt.subplots(figsize=(25, 12))\n",
    "\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    if num_jobs > len(colors):\n",
    "        random.seed(4487)\n",
    "        colors = []\n",
    "        for _ in range(num_jobs):\n",
    "            colors.append(f'#{random.randint(0, 0xFFFFFF):06x}')\n",
    "\n",
    "    for job_id, machine_id, stime, etime in result_job_schedule:\n",
    "        duration = etime - stime\n",
    "        rect = patches.Rectangle(\n",
    "            (stime, num_machines - machine_id - 1),\n",
    "            duration,\n",
    "            0.8,\n",
    "            linewidth=1,\n",
    "            edgecolor='black',\n",
    "            facecolor=colors[job_id],\n",
    "            alpha=0.6,\n",
    "            label=f'Job-{job_id}' if machine_id == 0 else ''\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        rx, ry = rect.get_xy()\n",
    "        ax.text(\n",
    "            rx + duration / 2,\n",
    "            ry + 0.4,\n",
    "            f'J{job_id}',\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            color='black',\n",
    "            fontweight='light'\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(0, max([endtime for _, _, _, endtime in result_job_schedule]) + 1)\n",
    "    ax.set_ylim(0, num_machines)\n",
    "\n",
    "    ax.set_yticks(np.arange(num_machines) + 0.4)\n",
    "    ax.set_yticklabels([f'Machine {num_machines - i - 1}' for i in range(num_machines)])\n",
    "\n",
    "    ax.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "    handles = [patches.Patch(color=colors[i], label=f'Job {i}') for i in range(num_jobs)]\n",
    "    ax.legend(handles=handles, loc='upper right', ncol=min(5, num_jobs))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machines')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebdd3a7e3355d",
   "metadata": {},
   "source": [
    "Define the main process of problem solving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9951b423873df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_flowshop(num_jobs, num_machines, jobs_data):\n",
    "\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    \"\"\"Create interval variables\"\"\"\n",
    "    intervals = {}\n",
    "    for job_id in range(num_jobs):\n",
    "        for task_id, (machine_id, duration) in enumerate(jobs_data[job_id]):\n",
    "            # a job is consisted of multiple tasks\n",
    "\n",
    "            unique_id = f'{job_id}-{machine_id}-{task_id}'\n",
    "            start = model.NewIntVar(0, 10000, f's-{unique_id}')\n",
    "            end = model.NewIntVar(0, 10000, f'e-{unique_id}')\n",
    "            interval = model.NewIntervalVar(start, duration, end, f'interval-{unique_id}')\n",
    "\n",
    "            # uniquely identified by job ID and machine ID\n",
    "            # since a task can only be executed on a machine\n",
    "            intervals[(job_id, machine_id)] = (start, end, interval)\n",
    "\n",
    "\n",
    "    \"\"\"Add constraints on the order\"\"\"\n",
    "    for job_id in range(num_jobs):\n",
    "        for task_id in range(1, num_machines):\n",
    "            # (task number = machine number) in flow-shop\n",
    "\n",
    "            prev_task_machine = jobs_data[job_id][task_id - 1][0]\n",
    "            cur_task_machine = jobs_data[job_id][task_id][0]\n",
    "\n",
    "            # start time of current task must be larger than the end time of previous task\n",
    "            model.Add(intervals[(job_id, cur_task_machine)][0]\n",
    "                      >= intervals[(job_id, prev_task_machine)][1])\n",
    "\n",
    "\n",
    "    \"\"\"Add constraints on the machine conflicts\"\"\"\n",
    "    for machine_id in range(num_machines):\n",
    "        machine_intervals = [\n",
    "            intervals[(job_id, machine_id)][2]\n",
    "            for job_id in range(num_jobs)\n",
    "        ]\n",
    "        model.AddNoOverlap(machine_intervals)\n",
    "\n",
    "\n",
    "    \"\"\"Setting Objects\"\"\"\n",
    "    case_object = model.NewIntVar(0, 10000, 'makespan')\n",
    "    model.AddMaxEquality(case_object, [\n",
    "        intervals[(job_id, num_machines-1)][1]\n",
    "        for job_id in range(num_jobs)\n",
    "    ])\n",
    "    model.Minimize(case_object)\n",
    "\n",
    "\n",
    "    \"\"\"Solving\"\"\"\n",
    "    solver = cp_model.CpSolver()\n",
    "    stat = solver.Solve(model)\n",
    "\n",
    "\n",
    "    \"\"\"Results\"\"\"\n",
    "    result_schedule = []\n",
    "    if stat == cp_model.OPTIMAL:\n",
    "        # exists optimal solution\n",
    "        print(f'Optimal Makespan: {solver.ObjectiveValue()}')\n",
    "        for job_id in range(num_jobs):\n",
    "            for machine_id in range(num_machines):\n",
    "                start = solver.Value(intervals[(job_id, machine_id)][0])\n",
    "                duration = jobs_data[job_id][machine_id][1]\n",
    "                end = start + duration\n",
    "                # print(f'Task-{machine_id} of Job-{job_id} is scheduled on Machine-{machine_id}: {start} ~ {end}')\n",
    "                result_schedule.append((job_id, machine_id, start, end))\n",
    "    else:\n",
    "        # No optimal solution\n",
    "        print('No solution found')\n",
    "\n",
    "    return result_schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e70776",
   "metadata": {},
   "source": [
    "This may take a long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f7a580594556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: data/carlier/carlier1.txt | Jobs: 11 | Machine: 5\n",
      "Optimal Makespan: 7038.0\n",
      "Sequence: [7, 2, 4, 3, 1, 10, 8, 9, 6, 0, 5]\n",
      "Time: 0.06935381889343262\n",
      "\n",
      "Problem: data/carlier/carlier2.txt | Jobs: 13 | Machine: 4\n",
      "Optimal Makespan: 7166.0\n",
      "Sequence: [2, 6, 3, 1, 8, 10, 0, 7, 11, 12, 5, 4, 9]\n",
      "Time: 0.07975029945373535\n",
      "\n",
      "Problem: data/heller/heller1.txt | Jobs: 100 | Machine: 10\n"
     ]
    }
   ],
   "source": [
    "for ins in instances:\n",
    "    (n_jobs, n_machines), jobs_data = read_cases(ins)\n",
    "    print(f\"Problem: {ins} | Jobs: {n_jobs} | Machine: {n_machines}\")\n",
    "\n",
    "    start = time.time()\n",
    "    result_schedule = solve_flowshop(n_jobs, n_machines, jobs_data)\n",
    "    time_spent = time.time() - start\n",
    "\n",
    "    machine_0_ops = [entry for entry in result_schedule if entry[1] == 0]\n",
    "    machine_0_ops.sort(key=lambda x: x[2])\n",
    "    sequence = [entry[0] for entry in machine_0_ops]\n",
    "    print(f\"Sequence: {sequence}\")\n",
    "    print(f\"Time: {time_spent}\\n\")\n",
    "\n",
    "    # plot_gantt_chart(result_schedule, n_jobs, n_machines, f'Result of case: {case_set_name}-{case_no}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1763bf6debef67",
   "metadata": {},
   "source": [
    "### Naïve Application on FunSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e57061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evolved_func_test.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e1969",
   "metadata": {},
   "source": [
    "This is the evolved NEH function using the naive application on FunSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evolved_neh(processing_times: np.ndarray) -> list[int]:\n",
    "    \"\"\"\n",
    "    An enhanced initial heuristic for the Permutation Flowshop Scheduling Problem (PFSP).\n",
    "\n",
    "    This heuristic combines:\n",
    "    - A weighted scoring for each job based on its total processing time and its maximum processing time.\n",
    "      The weight parameter alpha balances these two criteria.\n",
    "    - An iterative insertion procedure that builds an initial sequence.\n",
    "    - A subsequent local search using pairwise swap improvements to further reduce the makespan.\n",
    "\n",
    "    The resulting schedule (a list of job indices) is returned.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    An improved heuristic for the Permutation Flowshop Scheduling Problem (PFSP) that minimizes makespan\n",
    "    by using a modified job ordering and insertion strategy.\n",
    "\n",
    "    The heuristic performs the following steps:\n",
    "    - Orders jobs based on their maximum processing time across all machines.\n",
    "    - Builds an initial sequence using a modified greedy insertion strategy.\n",
    "    - Applies a local search with pairwise swaps to optimize the sequence further.\n",
    "\n",
    "    The resulting schedule (a list of job indices) is returned.\n",
    "    \"\"\"\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "\n",
    "    # Step 1: Order jobs based on their maximum processing time across all machines\n",
    "    job_indices = np.arange(num_jobs)\n",
    "    job_order = job_indices[np.argsort(-processing_times.max(axis=1))].tolist()\n",
    "\n",
    "    # Step 2: Build an initial sequence using a modified greedy insertion strategy\n",
    "    sequence = []\n",
    "    for job in job_order:\n",
    "        best_position = 0\n",
    "        best_makespan = float('inf')\n",
    "\n",
    "        # Try inserting the job in every possible position\n",
    "        for pos in range(len(sequence) + 1):\n",
    "            candidate_seq = sequence[:pos] + [job] + sequence[pos:]\n",
    "            ms = calc_makespan(candidate_seq, processing_times)\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_position = pos\n",
    "\n",
    "        # Insert the job at the best position found\n",
    "        sequence.insert(best_position, job)\n",
    "\n",
    "    # Step 3: Local search: try pairwise swaps to further improve the sequence\n",
    "    improvement = True\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        current_makespan = calc_makespan(sequence, processing_times)\n",
    "\n",
    "        for i in range(num_jobs - 1):\n",
    "            for j in range(i + 1, num_jobs):\n",
    "                new_seq = sequence.copy()\n",
    "                new_seq[i], new_seq[j] = new_seq[j], new_seq[i]\n",
    "                new_makespan = calc_makespan(new_seq, processing_times)\n",
    "\n",
    "                if new_makespan < current_makespan:\n",
    "                    sequence = new_seq\n",
    "                    current_makespan = new_makespan\n",
    "                    improvement = True\n",
    "                    # Break out to restart the search after any improvement\n",
    "                    break\n",
    "            if improvement:\n",
    "                break\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e43e2d",
   "metadata": {},
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f5bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: data/carlier/carlier1.txt | Jobs: 11 | Machines: 5\n",
      "Sequence: [7, 0, 4, 2, 10, 3, 5, 6, 8, 1, 9]\n",
      "Makespan: 7038.0\n",
      "Time: 0.01014399528503418\n",
      "\n",
      "Problem: data/carlier/carlier2.txt | Jobs: 13 | Machines: 4\n",
      "Sequence: [6, 10, 12, 2, 3, 4, 0, 1, 8, 7, 11, 9, 5]\n",
      "Makespan: 7376.0\n",
      "Time: 0.009727001190185547\n",
      "\n",
      "Problem: data/heller/heller2.txt | Jobs: 20 | Machines: 10\n",
      "Sequence: [0, 13, 12, 3, 8, 19, 7, 17, 16, 15, 2, 5, 11, 18, 14, 9, 1, 6, 10, 4]\n",
      "Makespan: 139.0\n",
      "Time: 0.0347440242767334\n",
      "\n",
      "Problem: data/reeves/reeves10.txt | Jobs: 30 | Machines: 10\n",
      "Sequence: [13, 12, 28, 5, 6, 4, 17, 21, 10, 2, 9, 23, 19, 1, 20, 8, 0, 14, 29, 3, 26, 24, 22, 7, 11, 16, 15, 18, 25, 27]\n",
      "Makespan: 2132.0\n",
      "Time: 0.17785286903381348\n",
      "\n",
      "Problem: data/reeves/reeves15.txt | Jobs: 30 | Machines: 15\n",
      "Sequence: [28, 14, 25, 3, 22, 5, 11, 24, 6, 27, 9, 13, 10, 23, 0, 29, 4, 19, 1, 15, 16, 21, 8, 2, 20, 26, 17, 12, 7, 18]\n",
      "Makespan: 2391.0\n",
      "Time: 0.336378812789917\n",
      "\n",
      "Problem: data/reeves/reeves20.txt | Jobs: 75 | Machines: 20\n",
      "Sequence: [48, 44, 19, 18, 47, 7, 16, 4, 32, 25, 65, 15, 10, 50, 43, 3, 39, 35, 9, 2, 23, 46, 57, 29, 67, 33, 53, 60, 30, 58, 31, 5, 24, 8, 74, 51, 27, 56, 41, 34, 21, 1, 11, 0, 22, 62, 38, 52, 49, 42, 55, 20, 45, 14, 61, 64, 13, 72, 71, 63, 40, 68, 36, 37, 28, 17, 12, 69, 73, 66, 26, 54, 70, 6, 59]\n",
      "Makespan: 5353.0\n",
      "Time: 2.5521607398986816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ins in instances:\n",
    "    directory = '/'.join(ins.split('/')[:-1])\n",
    "    filename = ins.split('/')[-1]\n",
    "    fs_data = load_datasets(directory)[filename]\n",
    "    fs_data = np.array(fs_data)\n",
    "\n",
    "    num_jobs, num_machines = fs_data.shape\n",
    "\n",
    "    print(f\"Problem: {ins} | Jobs: {num_jobs} | Machines: {num_machines}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    schedule = evolved_neh(fs_data)\n",
    "    time_spent = time.time() - start_time\n",
    "\n",
    "    final_makespan = calc_makespan(schedule, fs_data)\n",
    "\n",
    "    print(f\"Sequence: {schedule}\")\n",
    "    print(f\"Makespan: {final_makespan}\")\n",
    "    print(f\"Time: {time_spent}\\n\")\n",
    "\n",
    "    # plot_gantt_chart(schedule, fs_data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b2dae9c8ce707",
   "metadata": {},
   "source": [
    "## New Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd4c0dba4b1330",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126dd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_makespan(schedule: list[int], processing_times: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Compute the makespan (total completion time) for a given job schedule in a PFSP.\n",
    "    - schedule: list of job indices in the order they are processed.\n",
    "    - processing_times: 2D numpy array of shape (num_jobs, num_machines) with processing times for each job on each machine.\n",
    "    Returns the makespan (int) for the given order.\n",
    "    \"\"\"\n",
    "    num_jobs = len(schedule)\n",
    "    num_machines = processing_times.shape[1]\n",
    "    if num_jobs == 0:\n",
    "        return 0\n",
    "\n",
    "    completion_times = np.zeros((num_jobs, num_machines), dtype=int)\n",
    "    first_job = schedule[0]\n",
    "    completion_times[0, 0] = processing_times[first_job, 0]\n",
    "    for m in range(1, num_machines):\n",
    "        completion_times[0, m] = completion_times[0, m - 1] + processing_times[first_job, m]\n",
    "\n",
    "    for i in range(1, num_jobs):\n",
    "        job = schedule[i]\n",
    "        completion_times[i, 0] = completion_times[i - 1, 0] + processing_times[job, 0]\n",
    "        for m in range(1, num_machines):\n",
    "            completion_times[i, m] = max(completion_times[i, m - 1], completion_times[i - 1, m]) + processing_times[\n",
    "                job, m]\n",
    "\n",
    "    return int(completion_times[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e31b8",
   "metadata": {},
   "source": [
    "This is the skeleton provided to be improved.\n",
    "- The *average makespan* applied to training set is 4299.45 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66362ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_heuristic(processing_times: np.ndarray) -> list[int]:\n",
    "    \"\"\"\n",
    "    An enhanced initial heuristic for the Permutation Flowshop Scheduling Problem (PFSP).\n",
    "\n",
    "    This heuristic combines:\n",
    "    - A weighted scoring for each job based on its total processing time and its maximum processing time.\n",
    "      The weight parameter alpha balances these two criteria.\n",
    "    - An iterative insertion procedure that builds an initial sequence.\n",
    "    - A subsequent local search using pairwise swap improvements to further reduce the makespan.\n",
    "\n",
    "    The resulting schedule (a list of job indices) is returned.\n",
    "    \"\"\"\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "    alpha = 0.7  # Weight parameter: can be tuned/evolved (alpha in [0, 1])\n",
    "\n",
    "    # Compute a weighted score for each job.\n",
    "    # Lower score indicates a job should be scheduled earlier.\n",
    "    job_scores = []\n",
    "    for job in range(num_jobs):\n",
    "        total_time = processing_times[job].sum()\n",
    "        max_time = processing_times[job].max()\n",
    "        score = alpha * total_time + (1 - alpha) * max_time\n",
    "        job_scores.append((job, score))\n",
    "\n",
    "    # Sort jobs by ascending score (best candidate first)\n",
    "    job_scores.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Build an initial sequence using iterative insertion\n",
    "    sequence = [job_scores[0][0]]\n",
    "    for job, _ in job_scores[1:]:\n",
    "        best_sequence = None\n",
    "        best_makespan = float('inf')\n",
    "        # Try inserting the job in every possible position\n",
    "        for pos in range(len(sequence) + 1):\n",
    "            candidate_seq = sequence[:pos] + [job] + sequence[pos:]\n",
    "            ms = compute_makespan(candidate_seq, processing_times)\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_sequence = candidate_seq\n",
    "        sequence = best_sequence\n",
    "\n",
    "    # Local search: try pairwise swaps to further improve the sequence\n",
    "    improvement = True\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        current_makespan = compute_makespan(sequence, processing_times)\n",
    "        for i in range(num_jobs - 1):\n",
    "            for j in range(i + 1, num_jobs):\n",
    "                new_seq = sequence.copy()\n",
    "                new_seq[i], new_seq[j] = new_seq[j], new_seq[i]\n",
    "                new_makespan = compute_makespan(new_seq, processing_times)\n",
    "                if new_makespan < current_makespan:\n",
    "                    sequence = new_seq\n",
    "                    current_makespan = new_makespan\n",
    "                    improvement = True\n",
    "                    # Break out to restart the search after any improvement\n",
    "                    break\n",
    "            if improvement:\n",
    "                break\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ins in instances:\n",
    "    directory = '/'.join(ins.split('/')[:-1])\n",
    "    filename = ins.split('/')[-1]\n",
    "    fs_data = load_datasets(directory)[filename]\n",
    "    fs_data = np.array(fs_data)\n",
    "\n",
    "    num_jobs, num_machines = fs_data.shape\n",
    "\n",
    "    print(f\"\\nProblem: {ins} | Jobs: {num_jobs} | Machines: {num_machines}\")\n",
    "    \n",
    "    # Evaluate each variant\n",
    "    for variant in neh_variants:\n",
    "        variant_name = variant.__name__\n",
    "        print(f\"\\nEvaluating {variant_name}:\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        schedule = variant(fs_data)\n",
    "        time_spent = time.time() - start_time\n",
    "\n",
    "        final_makespan = calc_makespan(schedule, fs_data)\n",
    "\n",
    "        print(f\"Sequence: {schedule}\")\n",
    "        print(f\"Makespan: {final_makespan}\")\n",
    "        print(f\"Time: {time_spent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91349ac",
   "metadata": {},
   "source": [
    "When using base prompt with only goal:  \n",
    "\n",
    "        \"Improve the scheduling heuristic to minimize makespan. \"  \n",
    "        \"Only generate neh_heuristic(processing_times: np.ndarray) function.\"  \n",
    "        \"Only output the Python code, no descriptions.\" \n",
    "    \n",
    "     \n",
    "- There is no changed applied to the neh_heuristic function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c57d2a",
   "metadata": {},
   "source": [
    "This is the evolved NEH function using base prompt with little tips:  \n",
    "\n",
    "        \"Complete a different and more complex Python function.\"  \n",
    "        \"Be creative and you can insert multiple if-else and for-loop in the code logic.\"  \n",
    "        \"Only output the Python code, no descriptions.\"\n",
    "\n",
    "- The *average makespan* applied to training set is 4290.64 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a89320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_heuristic_base(processing_times: np.ndarray) -> list[int]:\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "    alpha = 0.7  # Weight parameter\n",
    "\n",
    "    job_scores = []\n",
    "    for job in range(num_jobs):\n",
    "        total_time = processing_times[job].sum()\n",
    "        max_time = processing_times[job].max()\n",
    "        score = alpha * total_time + (1 - alpha) * max_time\n",
    "        job_scores.append((job, score))\n",
    "\n",
    "    job_scores.sort(key=lambda x: x[1])\n",
    "\n",
    "    sequence = [job_scores[0][0]]\n",
    "    for job, _ in job_scores[1:]:\n",
    "        best_sequence = None\n",
    "        best_makespan = float('inf')\n",
    "        for pos in range(len(sequence) + 1):\n",
    "            candidate_seq = sequence[:pos] + [job] + sequence[pos:]\n",
    "            ms = compute_makespan(candidate_seq, processing_times)\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_sequence = candidate_seq\n",
    "        sequence = best_sequence\n",
    "\n",
    "    improvement = True\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        current_makespan = compute_makespan(sequence, processing_times)\n",
    "        for i in range(num_jobs - 1):\n",
    "            for j in range(i + 1, num_jobs):\n",
    "                new_seq = sequence.copy()\n",
    "                new_seq[i], new_seq[j] = new_seq[j], new_seq[i]\n",
    "                new_makespan = compute_makespan(new_seq, processing_times)\n",
    "                if new_makespan < current_makespan:\n",
    "                    sequence = new_seq\n",
    "                    current_makespan = new_makespan\n",
    "                    improvement = True\n",
    "                    break\n",
    "            if improvement:\n",
    "                break\n",
    "\n",
    "    # Additional logic for further improvement\n",
    "    for i in range(num_jobs):\n",
    "        for j in range(i + 1, num_jobs):\n",
    "            for k in range(j + 1, num_jobs):\n",
    "                temp_seq = sequence.copy()\n",
    "                temp_seq[i], temp_seq[j], temp_seq[k] = temp_seq[j], temp_seq[k], temp_seq[i]\n",
    "                temp_makespan = compute_makespan(temp_seq, processing_times)\n",
    "                if temp_makespan < current_makespan:\n",
    "                    sequence = temp_seq\n",
    "                    current_makespan = temp_makespan\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d608b8",
   "metadata": {},
   "source": [
    "This is the evolved NEH function using Instructive prompt with Open-ended:  \n",
    "\n",
    "        \"Improve the scheduling heuristic to minimize makespan.\"  \n",
    "        \"You can change how jobs are ordered or inserted,\" \n",
    "        \"Be creative. Think beyond NEH logic.\"\n",
    "        \"Please only generate neh_heuristic(processing_times: np.ndarray) function\"  \n",
    "        \"Use loops, conditionals, or clustering ideas. Only return valid Python code.\"  \n",
    "        \"Improve the scheduling heuristic to minimize makespan.\"\n",
    "        \"You can change how jobs are ordered or inserted,\"\n",
    "        \"Be creative. Think beyond NEH logic.\"\n",
    "        \"Please only generate neh_heuristic(processing_times: np.ndarray) function\"\n",
    "        \"Use loops, conditionals, or clustering ideas. Only return valid Python code.\"\n",
    "\n",
    "- The *average makespan* applied to training set is 4274.909 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_heuristic_intruct_Open_ended(processing_times: np.ndarray) -> list[int]:\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "\n",
    "    # Calculate a score for each job based on the total processing time across machines\n",
    "    job_scores = [(job, sum(processing_times[job])) for job in range(num_jobs)]\n",
    "\n",
    "    # Sort jobs in descending order of scores\n",
    "    job_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Initialize the sequence with the job of highest score\n",
    "    sequence = [job_scores[0][0]]\n",
    "\n",
    "    # Iterate through remaining jobs based on their score and insert at the position that minimizes makespan\n",
    "    for job, _ in job_scores[1:]:\n",
    "        best_position = 0\n",
    "        best_makespan = float('inf')\n",
    "        for pos in range(len(sequence) + 1):\n",
    "            candidate_seq = sequence[:pos] + [job] + sequence[pos:]\n",
    "            ms = compute_makespan(candidate_seq, processing_times)\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_position = pos\n",
    "        sequence = sequence[:best_position] + [job] + sequence[best_position:]\n",
    "\n",
    "    # Local search: use pairwise swaps to further improve the sequence\n",
    "    improvement = True\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        current_makespan = compute_makespan(sequence, processing_times)\n",
    "        for i in range(num_jobs - 1):\n",
    "            for j in range(i + 1, num_jobs):\n",
    "                new_seq = sequence.copy()\n",
    "                new_seq[i], new_seq[j] = new_seq[j], new_seq[i]\n",
    "                new_makespan = compute_makespan(new_seq, processing_times)\n",
    "                if new_makespan < current_makespan:\n",
    "                    sequence = new_seq\n",
    "                    current_makespan = new_makespan\n",
    "                    improvement = True\n",
    "                    break\n",
    "\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136bfd8",
   "metadata": {},
   "source": [
    "This is the evolved NEH function using Instructive prompt with Orientation:  \n",
    "\n",
    "      \"\"\"Improve the NEH heuristic for PFSP to minimize makespan. Focus on:\"\n",
    "          1. **Scoring Strategy**: Modify how jobs are prioritized (e.g., dynamic alpha, machine load balancing).\n",
    "          2. **Insertion Logic**: Optimize the position selection during insertion (e.g., early termination if no improvement).\n",
    "          3. **Local Search**: Replace the swap-based search with more efficient methods (e.g., 3-opt, tabu search).\n",
    "          4. **Constraints**:\n",
    "            - Preserve job uniqueness (no duplicates).\n",
    "            - Only use `compute_makespan` for evaluation.\n",
    "            - Return a list of job indices (e.g., [0, 2, 1]).\n",
    "          Generate *only* the `neh_heuristic` function body (no duplicate code from skeleton).\n",
    "           Only return python code.\n",
    "      \"\"\"\n",
    "\n",
    "- The *average makespan* applied to training set is 4298.182 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_heuristic_intruct_Orientation(processing_times: np.ndarray) -> list[int]:\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "    alpha = 0.7  # Weight parameter: can be tuned/evolved (alpha in [0, 1])\n",
    "    \n",
    "    # Step 1: Implement a more sophisticated scoring strategy (e.g., dynamic alpha, machine load balancing)\n",
    "    job_order = sorted(range(num_jobs), key=lambda x: np.max(processing_times[x]) - alpha * np.sum(processing_times[x]))\n",
    "    \n",
    "    # Step 2: Optimize the insertion logic to improve position selection during insertion\n",
    "    schedule = []\n",
    "    for job in job_order:\n",
    "        best_position = 0\n",
    "        best_makespan = compute_makespan(schedule[:best_position] + [job] + schedule[best_position:], processing_times)\n",
    "        for pos in range(1, len(schedule) + 1):\n",
    "            new_makespan = compute_makespan(schedule[:pos] + [job] + schedule[pos:], processing_times)\n",
    "            if new_makespan < best_makespan:\n",
    "                best_position = pos\n",
    "                best_makespan = new_makespan\n",
    "        schedule.insert(best_position, job)\n",
    "    \n",
    "    # Step 3: Implement a more efficient local search method (e.g., 3-opt, tabu search) to further improve makespan\n",
    "    \n",
    "    return schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db43113",
   "metadata": {},
   "source": [
    "This is the evolved NEH function using rag-type prompt with reverse engineering:  \n",
    "  \n",
    "        You are designing a scheduling heuristic for the Permutation Flowshop Scheduling Problem (PFSP) to minimize makespan.\n",
    "        To assist you, here is background knowledge about a powerful heuristic known as **NEH** (Nawaz–Enscore–Ham):\n",
    "        ----------------------------\n",
    "        [NEH Algorithm Knowledge Base]\n",
    "        1. **NEH Core Idea**:\n",
    "        - For each job, compute its total processing time across all machines.\n",
    "        - Sort jobs in descending order of total processing time.\n",
    "        - Build the schedule iteratively by inserting each job into the current partial sequence at the position that minimizes makespan.\n",
    "        2. **Example**:\n",
    "        - If sorted job order is [2, 0, 1], we start with [2], then try inserting job 0 into all positions: [0,2], [2,0], and pick the one with the smallest makespan.\n",
    "        - Repeat for job 1, trying all positions in the current sequence.\n",
    "        3. **Possible Enhancements**:\n",
    "        - Replace total processing time with weighted score (e.g., max(machine-wise time), early-machine dominance).\n",
    "        - Prune insertion positions that are unlikely to improve makespan.\n",
    "        - Use a local search after initial construction (e.g., 2-opt, job reordering).\n",
    "        ----------------------------\n",
    "        Now, imagine you are analyzing a **highly optimized black-box scheduler** whose logic is unknown.\n",
    "        Your task is to **reverse-engineer its internal heuristic**, assuming it is based on some modification of NEH.\n",
    "        Reconstruct the likely job scoring strategy, insertion policy, and local refinement steps it may be using.\n",
    "        **Constraints**:\n",
    "        - Use `compute_makespan(schedule, processing_times)` for evaluation only.\n",
    "        - Ensure schedule is a valid permutation (no job repetition).\n",
    "        - Only output the body of `neh_heuristic(processing_times: np.ndarray)` in valid Python code.\n",
    "\n",
    "- The *average makespan* applied to training set is 4280.00 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neh_heuristic_rag(processing_times: np.ndarray) -> list[int]:\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "    alpha = 0.7  # Weight parameter for job scoring\n",
    "\n",
    "    # Compute a weighted score for each job\n",
    "    job_scores = []\n",
    "    for job in range(num_jobs):\n",
    "        total_time = processing_times[job].sum()\n",
    "        max_time = processing_times[job].max()\n",
    "        score = alpha * total_time + (1 - alpha) * max_time\n",
    "        job_scores.append((job, score))\n",
    "\n",
    "    # Sort jobs by descending score\n",
    "    job_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Initialize an empty schedule\n",
    "    schedule = []\n",
    "    \n",
    "    # Insert jobs in sequence with minimum makespan\n",
    "    for job, _ in job_scores:\n",
    "        best_seq = None\n",
    "        best_makespan = float('inf')\n",
    "        for pos in range(len(schedule) + 1):\n",
    "            candidate_seq = schedule[:pos] + [job] + schedule[pos:]\n",
    "            ms = compute_makespan(candidate_seq, processing_times)\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_seq = candidate_seq\n",
    "        schedule = best_seq\n",
    "\n",
    "    # Local search: pairwise swaps for further improvement\n",
    "    improvement = True\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        current_makespan = compute_makespan(schedule, processing_times)\n",
    "        for i in range(num_jobs - 1):\n",
    "            for j in range(i + 1, num_jobs):\n",
    "                new_seq = schedule.copy()\n",
    "                new_seq[i], new_seq[j] = new_seq[j], new_seq[i]\n",
    "                new_makespan = compute_makespan(new_seq, processing_times)\n",
    "                if new_makespan < current_makespan:\n",
    "                    schedule = new_seq\n",
    "                    current_makespan = new_makespan\n",
    "                    improvement = True\n",
    "                    break  # Restart search after each improvement\n",
    "            if improvement:\n",
    "                break\n",
    "\n",
    "    return schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec46d0",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638285dcccf1a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all NEH variants to evaluate\n",
    "neh_variants = [\n",
    "    neh_heuristic,\n",
    "    neh_heuristic_base,\n",
    "    neh_heuristic_intruct_Open_ended,\n",
    "    neh_heuristic_intruct_Orientation,\n",
    "    neh_heuristic_rag,\n",
    "]\n",
    "\n",
    "for ins in instances:\n",
    "    directory = '/'.join(ins.split('/')[:-1])\n",
    "    filename = ins.split('/')[-1]\n",
    "    fs_data = load_datasets(directory)[filename]\n",
    "    fs_data = np.array(fs_data)\n",
    "\n",
    "    num_jobs, num_machines = fs_data.shape\n",
    "\n",
    "    print(f\"\\nProblem: {ins} | Jobs: {num_jobs} | Machines: {num_machines}\")\n",
    "    \n",
    "    # Evaluate each variant\n",
    "    for variant in neh_variants:\n",
    "        variant_name = variant.__name__\n",
    "        print(f\"\\nEvaluating {variant_name}:\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        schedule = variant(fs_data)\n",
    "        time_spent = time.time() - start_time\n",
    "\n",
    "        final_makespan = calc_makespan(schedule, fs_data)\n",
    "\n",
    "        print(f\"Sequence: {schedule}\")\n",
    "        print(f\"Makespan: {final_makespan}\")\n",
    "        print(f\"Time: {time_spent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf527d2cdc8a943",
   "metadata": {},
   "source": [
    "### FunSearch with Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8babde0e35b8e83c",
   "metadata": {},
   "source": [
    "This is our key improvements that has made on the basic FunSearch Framework. The main idea of the new framework is applying **Curriculum Learning** in the evolving process of FunSearch.\n",
    "\n",
    "Specifically, a single iteration of evolving is now turned into multiple iterations. In this framework, we call them 'Stages':\n",
    "- The input instances are divided into various stages, starting from 'easy' instances all the way up to 'complicated' instances\n",
    "    - Degrees of complication are defined manually\n",
    "- At each stage, FunSearch is executed only with the instances belong to that stage, and gets the result\n",
    "- If the result of current stage is higher than the baseline score, then it enters the next stage, namely a more complicated stage\n",
    "    - Baseline function that provides baseline score is given by the raw function at each stage before the actual evolving\n",
    "- If the result of current stage is lower than the baseline score, it keeps trying until it reaches the maximum number of attempts defined in advance, or gets a better score and escapes current stage\n",
    "- The final output of this framework can either be the 'semi-evolved' or 'completely-evolved' function due to the maximum attempts limit\n",
    "\n",
    "> See directory `implementation_cl` for the detailed implementation of this framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237b5b6",
   "metadata": {},
   "source": [
    "This is the evolved NEH function using our FunSearch-CL framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784d2cc54cb3112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_makespan(schedule: list[int], processing_times: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Compute the makespan (total completion time) for a given job schedule in a PFSP.\n",
    "    - schedule: list of job indices in the order they are processed.\n",
    "    - processing_times: 2D numpy array of shape (num_jobs, num_machines) with processing times for each job on each machine.\n",
    "    Returns the makespan (int) for the given order.\n",
    "    \"\"\"\n",
    "    num_jobs = len(schedule)\n",
    "    num_machines = processing_times.shape[1]\n",
    "    if num_jobs == 0:\n",
    "        return 0\n",
    "\n",
    "    completion_times = np.zeros((num_jobs, num_machines), dtype=int)\n",
    "    first_job = schedule[0]\n",
    "    completion_times[0, 0] = processing_times[first_job, 0]\n",
    "    for m in range(1, num_machines):\n",
    "        completion_times[0, m] = completion_times[0, m - 1] + processing_times[first_job, m]\n",
    "\n",
    "    for i in range(1, num_jobs):\n",
    "        job = schedule[i]\n",
    "        completion_times[i, 0] = completion_times[i - 1, 0] + processing_times[job, 0]\n",
    "        for m in range(1, num_machines):\n",
    "            completion_times[i, m] = max(completion_times[i, m - 1], completion_times[i - 1, m]) + processing_times[\n",
    "                job, m]\n",
    "\n",
    "    return int(completion_times[-1, -1])\n",
    "\n",
    "\n",
    "def evolved_neh_cl(processing_times: np.ndarray) -> list[int]:\n",
    "    import random\n",
    "    num_jobs, num_machines = processing_times.shape\n",
    "\n",
    "    def compute_priority_scores():\n",
    "        scores = []\n",
    "        weights = np.linspace(1.5, 0.5, num=num_machines)\n",
    "        weighted_sums = processing_times @ weights\n",
    "        for j in range(num_jobs):\n",
    "            bottleneck = np.max(processing_times[j])\n",
    "            score = 0.7 * weighted_sums[j] + 0.2 * processing_times[j].sum() + 0.1 * bottleneck\n",
    "            scores.append((j, score))\n",
    "        return sorted(scores, key=lambda x: -x[1])\n",
    "\n",
    "    def dynamic_insertion(seq, job_id):\n",
    "        best_seq = None\n",
    "        best_makespan = float('inf')\n",
    "        for i in range(len(seq) + 1):\n",
    "            candidate = seq[:i] + [job_id] + seq[i:]\n",
    "            ms = compute_makespan(candidate, processing_times)\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_seq = candidate\n",
    "        return best_seq\n",
    "\n",
    "    def balance_machine_load(sequence):\n",
    "        loads = np.zeros((num_machines,))\n",
    "        for job in sequence:\n",
    "            loads += processing_times[job]\n",
    "        return np.std(loads)\n",
    "\n",
    "    def tabu_local_search(init_seq, tabu_tenure=5, max_iter=100):\n",
    "        current_seq = init_seq[:]\n",
    "        best_seq = current_seq[:]\n",
    "        best_makespan = compute_makespan(best_seq, processing_times)\n",
    "        tabu_list = {}\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < max_iter:\n",
    "            neighborhood = []\n",
    "            for i in range(num_jobs):\n",
    "                for j in range(i + 1, num_jobs):\n",
    "                    if (i, j) in tabu_list and tabu_list[(i, j)] > iteration:\n",
    "                        continue\n",
    "                    temp_seq = current_seq[:]\n",
    "                    temp_seq[i], temp_seq[j] = temp_seq[j], temp_seq[i]\n",
    "                    ms = compute_makespan(temp_seq, processing_times)\n",
    "                    load_dev = balance_machine_load(temp_seq)\n",
    "                    score = ms + 0.01 * load_dev\n",
    "                    neighborhood.append((score, ms, (i, j), temp_seq))\n",
    "\n",
    "            if not neighborhood:\n",
    "                break\n",
    "\n",
    "            neighborhood.sort()\n",
    "            score, ms, move, candidate_seq = neighborhood[0]\n",
    "            current_seq = candidate_seq[:]\n",
    "            tabu_list[move] = iteration + tabu_tenure\n",
    "\n",
    "            if ms < best_makespan:\n",
    "                best_makespan = ms\n",
    "                best_seq = current_seq[:]\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        return best_seq\n",
    "\n",
    "    def adaptive_restart(base_seq, num_restarts=4):\n",
    "        best_seq = base_seq[:]\n",
    "        best_ms = compute_makespan(best_seq, processing_times)\n",
    "        for r in range(num_restarts):\n",
    "            shuffled = base_seq[:]\n",
    "            random.shuffle(shuffled)\n",
    "            evolved = tabu_local_search(shuffled, max_iter=30)\n",
    "            ms = compute_makespan(evolved, processing_times)\n",
    "            if ms < best_ms:\n",
    "                best_ms = ms\n",
    "                best_seq = evolved\n",
    "        return best_seq\n",
    "\n",
    "    scored_jobs = compute_priority_scores()\n",
    "    ordered_jobs = [j for j, _ in scored_jobs]\n",
    "\n",
    "    sequence = []\n",
    "    for job in ordered_jobs:\n",
    "        sequence = dynamic_insertion(sequence, job)\n",
    "\n",
    "    sequence = tabu_local_search(sequence)\n",
    "    sequence = adaptive_restart(sequence, num_restarts=5)\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f825f",
   "metadata": {},
   "source": [
    "Get the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b3ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: data/carlier/carlier1.txt | Jobs: 11 | Machines: 5\n",
      "Sequence: [7, 0, 2, 4, 3, 10, 8, 6, 1, 9, 5]\n",
      "Makespan: 7038.0\n",
      "Time: 0.4140651226043701\n",
      "\n",
      "Problem: data/carlier/carlier2.txt | Jobs: 13 | Machines: 4\n",
      "Sequence: [6, 2, 3, 10, 12, 0, 1, 8, 7, 11, 4, 9, 5]\n",
      "Makespan: 7166.0\n",
      "Time: 0.5460460186004639\n",
      "\n",
      "Problem: data/heller/heller2.txt | Jobs: 20 | Machines: 10\n",
      "Sequence: [0, 1, 15, 19, 13, 18, 14, 3, 12, 8, 7, 11, 16, 2, 17, 5, 9, 10, 6, 4]\n",
      "Makespan: 137.0\n",
      "Time: 4.241786956787109\n",
      "\n",
      "Problem: data/reeves/reeves10.txt | Jobs: 30 | Machines: 10\n",
      "Sequence: [13, 28, 10, 2, 17, 1, 4, 6, 23, 22, 20, 9, 16, 7, 8, 0, 19, 3, 26, 14, 12, 24, 21, 29, 25, 5, 11, 15, 18, 27]\n",
      "Makespan: 2120.0\n",
      "Time: 14.38571810722351\n",
      "\n",
      "Problem: data/reeves/reeves15.txt | Jobs: 30 | Machines: 15\n",
      "Sequence: [28, 14, 3, 22, 5, 11, 6, 13, 23, 27, 9, 12, 0, 21, 15, 25, 7, 1, 29, 24, 26, 19, 2, 10, 17, 8, 20, 16, 4, 18]\n",
      "Makespan: 2332.0\n",
      "Time: 20.20167088508606\n",
      "\n",
      "Problem: data/reeves/reeves20.txt | Jobs: 75 | Machines: 20\n",
      "Sequence: [48, 7, 44, 32, 41, 16, 5, 19, 23, 27, 67, 35, 56, 43, 20, 33, 57, 65, 4, 15, 39, 62, 22, 53, 42, 68, 46, 45, 8, 1, 58, 25, 55, 51, 37, 50, 49, 18, 21, 40, 29, 17, 64, 9, 2, 0, 34, 31, 13, 52, 66, 10, 72, 24, 71, 69, 38, 74, 14, 61, 63, 30, 36, 60, 11, 12, 73, 28, 54, 47, 59, 3, 70, 6, 26]\n",
      "Makespan: 5247.0\n",
      "Time: 401.87142968177795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ins in instances:\n",
    "    directory = '/'.join(ins.split('/')[:-1])\n",
    "    filename = ins.split('/')[-1]\n",
    "    fs_data = load_datasets(directory)[filename]\n",
    "    fs_data = np.array(fs_data)\n",
    "\n",
    "    num_jobs, num_machines = fs_data.shape\n",
    "\n",
    "    print(f\"Problem: {ins} | Jobs: {num_jobs} | Machines: {num_machines}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    schedule = evolved_neh_cl(fs_data)\n",
    "    time_spent = time.time() - start_time\n",
    "\n",
    "    final_makespan = calc_makespan(schedule, fs_data)\n",
    "\n",
    "    print(f\"Sequence: {schedule}\")\n",
    "    print(f\"Makespan: {final_makespan}\")\n",
    "    print(f\"Time: {time_spent}\\n\")\n",
    "\n",
    "    # plot_gantt_chart(schedule, fs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6537eeb104fb003",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec360b",
   "metadata": {},
   "source": [
    "Then, we will compare these different approaches using various metrics.\n",
    "\n",
    "- Models:\n",
    "    - Baseline: Base NEH algorithm, Google OR-Tools, Base Evolved Function\n",
    "    - New Approaches: FunSearch Utilizing Prompt Engineering, FunSearch Incorporating Curriculum Learning\n",
    "\n",
    "- Metrics: Final Makespan, Rate of Increase in Makespan, Execution Time, Proportion of Improved Makespan Across All Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830d4e068c651b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funsearch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
